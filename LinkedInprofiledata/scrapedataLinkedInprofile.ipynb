{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libary Import"
      ],
      "metadata": {
        "id": "1u94AoYGhGrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n"
      ],
      "metadata": {
        "id": "W4Jx_gAehPkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload your zip files to Google Colab"
      ],
      "metadata": {
        "id": "imPAu-1NhNtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Upload your zip files to Google Colab\n",
        "\n",
        "# Define the directory where zip files are uploaded and where to extract them\n",
        "upload_dir = '/content/'\n",
        "extract_dir = '/content/drive/MyDrive/'"
      ],
      "metadata": {
        "id": "lqMn4gG7hZls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Create a directory for extracted files"
      ],
      "metadata": {
        "id": "Qvgxo9s2hdkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Function to extract all zip files\n",
        "def extract_zip_files(upload_dir, extract_dir):\n",
        "    for file_name in os.listdir(upload_dir):\n",
        "        if file_name.endswith('.zip'):\n",
        "            with zipfile.ZipFile(os.path.join(upload_dir, file_name), 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Extract zip files\n",
        "extract_zip_files(upload_dir, extract_dir)\n",
        "\n",
        "# Initialize an empty DataFrame to store the combined data\n",
        "combined_df = pd.DataFrame(columns=['country', 'year', 'variant', 'age_range', 'gender', 'population'])"
      ],
      "metadata": {
        "id": "VBhF82AHhizN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Combine CSV data into one DataFrame"
      ],
      "metadata": {
        "id": "nKgKqqXehqGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUdOEru6kz0C",
        "outputId": "95db553f-991c-4433-9d35-04bfb4475333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the combined DataFrame: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "for file_name in os.listdir(extract_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(extract_dir, file_name)\n",
        "        # Read CSV file and add necessary columns\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Extract country, year, variant, age_range, and gender from file name\n",
        "        country, year, variant, age_range, gender = file_name.split('_')\n",
        "        year = int(year)\n",
        "        age_range = age_range.split('.')[0]  # Remove file extension from age_range\n",
        "        gender = gender.split('.')[0]  # Remove file extension from gender\n",
        "        df['country'] = country\n",
        "        df['year'] = year\n",
        "        df['variant'] = variant\n",
        "        df['age_range'] = age_range\n",
        "        df['gender'] = gender\n",
        "        # Append to combined DataFrame\n",
        "        combined_df = pd.concat([combined_df, df])\n",
        "\n",
        "# Multiply 'population' column by 1000\n",
        "combined_df['population'] *= 1000\n",
        "\n",
        "# Print number of rows\n",
        "print(\"Number of rows in the combined DataFrame:\", len(combined_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Group by 'country', 'year', and 'age_range' and sum the populations for male and female separately"
      ],
      "metadata": {
        "id": "cwzNh-_Thxs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_population = combined_df.groupby(['country', 'year', 'age_range']).agg({'population': 'sum'}).reset_index()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(total_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NG8HI9Oux2x",
        "outputId": "29add2af-de86-43a3-a6aa-6c9f90e707d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [country, year, age_range, population]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload your zip files to Google Colab\n",
        "\n",
        "# Define the directory where zip files are uploaded and where to extract them"
      ],
      "metadata": {
        "id": "qbCpqXfCh21z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Upload your zip files to Google Colab\n",
        "\n",
        "# Define the directory where zip files are uploaded and where to extract them\n",
        "upload_dir = '/content/'\n",
        "extract_dir = '/content/drive/MyDrive/'\n",
        "\n",
        "# Create a directory for extracted files\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Function to extract all zip files\n",
        "def extract_zip_files(upload_dir, extract_dir):\n",
        "    for file_name in os.listdir(upload_dir):\n",
        "        if file_name.endswith('.zip'):\n",
        "            with zipfile.ZipFile(os.path.join(upload_dir, file_name), 'r') as zip_ref:\n",
        "                zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Extract zip files\n",
        "extract_zip_files(upload_dir, extract_dir)\n",
        "\n",
        "# Initialize an empty DataFrame to store the combined data\n",
        "combined_df = pd.DataFrame(columns=['country', 'year', 'variant', 'age_range', 'gender', 'population'])\n",
        "\n",
        "# Combine CSV data into one DataFrame\n",
        "for file_name in os.listdir(extract_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(extract_dir, file_name)\n",
        "        # Read CSV file and add necessary columns\n",
        "        df = pd.read_csv(file_path)\n",
        "        # Extract country, year, variant, age_range, and gender from file name\n",
        "        country, year, variant, age_range, gender = file_name.split('_')\n",
        "        year = int(year)\n",
        "        age_range = age_range.split('.')[0]  # Remove file extension from age_range\n",
        "        gender = gender.split('.')[0]  # Remove file extension from gender\n",
        "        df['country'] = country\n",
        "        df['year'] = year\n",
        "        df['variant'] = variant\n",
        "        df['age_range'] = age_range\n",
        "        df['gender'] = gender\n",
        "        # Append to combined DataFrame\n",
        "        combined_df = pd.concat([combined_df, df])\n",
        "\n",
        "# Multiply 'population' column by 1000\n",
        "combined_df['population'] *= 1000\n",
        "\n",
        "# Print the first few rows of the combined DataFrame\n",
        "print(\"First few rows of the combined DataFrame:\")\n",
        "print(combined_df.head())\n",
        "\n",
        "# Print unique values of 'country', 'year', and 'age_range'\n",
        "print(\"\\nUnique countries:\", combined_df['country'].unique())\n",
        "print(\"Unique years:\", combined_df['year'].unique())\n",
        "print(\"Unique age ranges:\", combined_df['age_range'].unique())\n",
        "\n",
        "# Group by 'country', 'year', and 'age_range' and sum the populations for male and female separately\n",
        "total_population = combined_df.groupby(['country', 'year', 'age_range']).agg({'population': 'sum'}).reset_index()\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(\"\\nTotal population DataFrame:\")\n",
        "print(total_population)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqhzSYiYvkHW",
        "outputId": "26e9ff96-2d6a-4392-9204-497f83963b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the combined DataFrame:\n",
            "Empty DataFrame\n",
            "Columns: [country, year, variant, age_range, gender, population]\n",
            "Index: []\n",
            "\n",
            "Unique countries: []\n",
            "Unique years: []\n",
            "Unique age ranges: []\n",
            "\n",
            "Total population DataFrame:\n",
            "Empty DataFrame\n",
            "Columns: [country, year, age_range, population]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine CSV data into one DataFrame"
      ],
      "metadata": {
        "id": "-j0jBWXth6Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for file_name in os.listdir(extract_dir):\n",
        "    if file_name.endswith('.csv'):\n",
        "        file_path = os.path.join(extract_dir, file_name)\n",
        "        # Read CSV file and add necessary columns\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"Reading file: {file_path}\")\n",
        "        print(\"Columns in CSV file:\", df.columns)\n",
        "        print(\"Number of rows in CSV file:\", len(df))\n",
        "        # Extract country, year, variant, age_range, and gender from file name\n",
        "        country, year, variant, age_range, gender = file_name.split('_')\n",
        "        year = int(year)\n",
        "        age_range = age_range.split('.')[0]  # Remove file extension from age_range\n",
        "        gender = gender.split('.')[0]  # Remove file extension from gender\n",
        "        print(\"Extracted information from file name:\")\n",
        "        print(\"Country:\", country)\n",
        "        print(\"Year:\", year)\n",
        "        print(\"Variant:\", variant)\n",
        "        print(\"Age Range:\", age_range)\n",
        "        print(\"Gender:\", gender)\n",
        "        df['country'] = country\n",
        "        df['year'] = year\n",
        "        df['variant'] = variant\n",
        "        df['age_range'] = age_range\n",
        "        df['gender'] = gender\n",
        "        # Append to combined DataFrame\n",
        "        combined_df = pd.concat([combined_df, df])\n",
        "\n",
        "print(\"\\nCombined DataFrame:\")\n",
        "print(combined_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0l8McRiv4Of",
        "outputId": "1bc60150-ebe4-4527-f8e4-f1229194cb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Combined DataFrame:\n",
            "Empty DataFrame\n",
            "Columns: [country, year, variant, age_range, gender, population]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to scrape data from a single LinkedIn profile"
      ],
      "metadata": {
        "id": "Cr3EgKBlh-LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n"
      ],
      "metadata": {
        "id": "HIRpO7cGiDkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to scrape data from a single LinkedIn profile"
      ],
      "metadata": {
        "id": "NQia8afriCt-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qPWQyYfliL0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to scrape multiple profiles from a LinkedIn Sales Navigator search results page"
      ],
      "metadata": {
        "id": "WK9oUv4FiKpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def scrape_profile(profile_url):\n",
        "    # Send a GET request to the profile URL\n",
        "    response = requests.get(profile_url)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract relevant information from the profile page\n",
        "        name = soup.find('span', class_='full-name').text.strip()\n",
        "        job_title = soup.find('p', class_='headline').text.strip()\n",
        "        # Add more fields as needed\n",
        "\n",
        "        return {'Name': name, 'Job Title': job_title}\n",
        "    else:\n",
        "        print(f\"Failed to retrieve profile: {profile_url}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "F57Tm1BPiOIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def scrape_search_results(search_url):\n",
        "    # Send a GET request to the search results URL\n",
        "    response = requests.get(search_url)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract profile URLs from the search results page\n",
        "        profile_urls = [a['href'] for a in soup.find_all('a', class_='profile-link')]\n",
        "\n",
        "        # Scrape data from each profile\n",
        "        profiles_data = []\n",
        "        for profile_url in profile_urls:\n",
        "            profile_data = scrape_profile(profile_url)\n",
        "            if profile_data:\n",
        "                profiles_data.append(profile_data)\n",
        "\n",
        "        return profiles_data\n",
        "    else:\n",
        "        print(f\"Failed to retrieve search results: {search_url}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "search_url = \"https://www.linkedin.com/sales/search/people?lastViewedAt=1693584622369&savedSearchId=50553125&sessionId=dT73ba93QgSloHu78N4DVw%3D%3D\"\n",
        "profiles_data = scrape_search_results(search_url)\n",
        "\n",
        "# Save data to a CSV file\n",
        "if profiles_data:\n",
        "    with open('linkedin_profiles.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Name', 'Job Title']  # Add more fields as needed\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for profile_data in profiles_data:\n",
        "            writer.writerow(profile_data)\n",
        "    print(\"Data saved to linkedin_profiles.csv\")\n"
      ],
      "metadata": {
        "id": "S2rUKimmRJHN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}